% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/tokenize.R
\name{tokenize}
\alias{tokenize}
\title{Recompute the tokens for a document or corpus}
\usage{
tokenize(x, tokenizer, ..., hash_func = hash_string, keep_tokens = TRUE,
  keep_text = TRUE)
}
\arguments{
\item{x}{A \code{\link{TextReuseTextDocument}} or \code{\link{TextReuseCorpus}}.}

\item{tokenizer}{A function to split the text into tokens. See
\code{\link{tokenizers}}.}

\item{...}{Arguments passed on to the \code{tokenizer}.}

\item{hash_func}{A function to hash the tokens. See
\code{\link{hash_string}}.}

\item{keep_tokens}{Should the tokens be saved in the document that is
returned or discarded?}

\item{keep_text}{Should the text be saved in the document that is returned or
discarded?}
}
\value{
The modified \code{\link{TextReuseTextDocument}} or \code{\link{TextReuseCorpus}}.
}
\description{
Given a \code{\link{TextReuseTextDocument}} or a
\code{\link{TextReuseCorpus}}, this function recomputes the tokens and hashes
with the functions specified.
}

