---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

## textreuse

An R package for detecting text reuse and document similarity in a corpus.

**Author:** [Lincoln Mullen](http://lincolnmullen.com)<br>
**License:** [MIT](http://opensource.org/licenses/MIT)<br>
**Status:** In development

[![CRAN\_Status\_Badge](http://www.r-pkg.org/badges/version/textreuse)](http://cran.r-project.org/package=textreuse)
[![CRAN\_Downloads](http://cranlogs.r-pkg.org/badges/grand-total/textreuse)](http://cran.r-project.org/package=textreuse)
[![Build Status](https://travis-ci.org/lmullen/textreuse.svg?branch=master)](https://travis-ci.org/lmullen/textreuse) 
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/lmullen/textreuse?branch=master)](https://ci.appveyor.com/project/lmullen/textreuse)

### Description 

This R package provides a set of functions for measuring similarity among documents and detecting passages which have been reused. It implements shingled n-gram, skip n-gram, and other tokenizers; similarity/dissimilarity functions; pairwise comparisons; and minhash and locality sensitive hashing algorithms.

The package was written to facilitate historical research among legal texts, but it is broadly useful for, for example, detecting duplicate documents in a corpus prior to text analysis. The classes provides by this package follow the model of other natural language processing packages for R, especially the [NLP](https://cran.r-project.org/package=NLP) and [tm](https://cran.r-project.org/package=tm) packages. (However, this package has no dependency on Java, which should make it easier to install.)

### Installation

This package is not yet on CRAN. To install it from GitHub, use [devtools](https://github.com/hadley/devtools). 

```{r eval=FALSE}
# install.packages("devtools")
devtools::install_github("lmullen/textreuse")
```

### Example

In this example we will load a tiny corpus of three documents. These documents are drawn from Kellen Funk's [research](http://kellenfunk.org/field-code/) into the propagation of legal codes of civil procedure in the nineteenth-century United States.

```{r}
library(textreuse)
dir <- system.file("extdata/legal", package = "textreuse")
corpus <- TextReuseCorpus(dir = dir, meta = list(title = "Civil procedure"),
                          tokenizer = tokenize_ngrams, n = 7)
```

We have loaded the three documents into a corpus, which involves tokenizing the text and hashing the tokens. We can inspect the corpus as a whole or the individual documents that make it up.

```{r}
corpus
corpus[["ca1851-match"]]
```

Now we can compare each of the documents to one another. The result is a matrix of scores. As we would expect, some documents are similar and others are not.

```{r}
comparisons <- pairwise_compare(corpus, jaccard_similarity)
comparisons
```

We can convert that matrix to a data frame of pairs and scores if we prefer.

```{r}
pairwise_candidates(comparisons)
```

Pairwise comparisons can be very time-consuming because they grow exponentially with the size of the corpus. (A corpus with 10 documents would require at least 45 comparisons; a corpus with 100 documents would require 4,950 comparisons; a corpus with 1,000 documents would require 499,500 comparisons.) That's why this package implements the minhash and locality sensitive hashing algorithms, which can detect candidate pairs much faster than pairwise comparisons in corpora of any significant size. For details, see the package vignettes.

```{r eval=FALSE}
vignette(package = "textreuse")
```

### Citation

If you use this package for scholarly research, I would appreciate a citation.

```{r}
citation("textreuse")
```

